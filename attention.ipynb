{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21fdebd2-0a73-4547-9ebe-0df47ad3ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26908c96-8475-424c-9c94-bfe39fb9b655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\te20312262\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, Bidirectional,\\\n",
    "                            RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3c24e5-5a74-4718-ac15-01e887aabf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    import keras.backend as K\n",
    "    if len(K.tensorflow_backend._get_available_gpus()) > 0:\n",
    "        from keras.layers import CuDNNLSTM as LSTM\n",
    "        from keras.layers import CuDNNGRU as GRU\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02108073-d8ba-4ffd-971d-89ff0f78b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we do softmax over the time axis\n",
    "# expected shape is N x T x D\n",
    "# note: the latest version of keras allows you to pass in axis arg\n",
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 2)\n",
    "    e = K.exp(x - K.max(x,axis=1,keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c339db-201b-4a7b-84b6-e475caf68d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LATENT_DIM = 400\n",
    "LATENT_DIM_DECODER = 400 # idea: make it different to ensure things all fit together properly!\n",
    "NUM_SAMPLES = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99eec90-d19c-4301-8da6-ad16880c512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we will store the data\n",
    "input_texts = [] # sentence in original language\n",
    "target_texts = [] # sentence in target language\n",
    "target_texts_inputs = [] # sentence in target language offset by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b32bdbe-f85b-4b69-abab-0f1ecd97cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num samples: 20000\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "# download the data at: http://www.manythings.org/anki/\n",
    "t = 0\n",
    "for line in open(\"./spa-eng/spa.txt\",encoding=\"utf-8\"):\n",
    "    # only keep a limited number of samples\n",
    "    t+=1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "        \n",
    "    # input and target are seperated by tab\n",
    "    if \"\\t\" not in line:\n",
    "        continue\n",
    "    # split up the input and translation\n",
    "    input_text, translation, *rest = line.rstrip().split(\"\\t\")\n",
    "\n",
    "    # make the target input and output\n",
    "    # recall we'll be using teacher forcing\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)\n",
    "print(\"num samples:\", len(input_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3c0a57-9c0e-49aa-93f0-e511c1393471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the inputs\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a611a82e-a0ef-4be1-b345-e8f47c9ad437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3746 unique input tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for input language\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89320b11-9370-4492-b35a-1da9bf9c1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine maximum length input sequence\n",
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3975ac4-3521-44d8-896b-cebc907e9274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the outputs\n",
    "# dont filter out special characters\n",
    "# otherwise <sos> and <eos> won't appear\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) # inefficient, oh well\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd6614d-3f67-4550-a003-e0ae2a1614d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10553 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# get the word to index mapping for output language\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print(\"Found %s unique output tokens.\" % len(word2idx_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17df43ae-c409-4217-a089-778790d110cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store number of output words for later\n",
    "# remember to add 1 since indexing starts at 1\n",
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09a32a9b-cf9a-48fa-bcd2-89d56af8b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine maximum length output sequence\n",
    "max_len_target = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65fe4e58-859b-4996-8b40-0f1c70664e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_data.shape: (20000, 6)\n",
      "encoder_data[0]: [ 0  0  0  0  0 21]\n",
      "decoder_data[0]: [   2 2811    0    0    0    0    0    0    0    0]\n",
      "decoder_data.shape: (20000, 10)\n"
     ]
    }
   ],
   "source": [
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "print(\"encoder_data.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_data[0]:\", encoder_inputs[0])\n",
    "\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target,padding='post')\n",
    "print(\"decoder_data[0]:\", decoder_inputs[0])\n",
    "print(\"decoder_data.shape:\", decoder_inputs.shape)\n",
    "\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd884ad-d987-488f-bfc8-944a02dd000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# store all the pre-trained word vectors\n",
    "print(\"Loading word vectors...\")\n",
    "word2vec = {}\n",
    "with open(\"glove.6B.100d.txt\",encoding=\"utf-8\") as f:\n",
    "    # is just a space-seperated text file in the format:\n",
    "    # word vec[0] vec[1] vec[2] ...\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "    print(\"Found %s word vectors.\" % len(word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4187dac6-07f4-4720-9d42-d05bd9d0b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print(\"Filling pre-trained embeddings...\")\n",
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba38f1e-ccd2-4488-86dc-c79a3e57f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\te20312262\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix],input_length=max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f9d7d5-596a-4a0c-99cb-c0309f167533",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.86 GiB for an array with shape (20000, 10, 10554) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create targets, since we cannot use sparse\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# categorical cross entropy when we have sequences\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m decoder_targets_one_hot \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_texts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_words_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.86 GiB for an array with shape (20000, 10, 10554) and data type float32"
     ]
    }
   ],
   "source": [
    "# create targets, since we cannot use sparse\n",
    "# categorical cross entropy when we have sequences\n",
    "decoder_targets_one_hot = np.zeros((len(input_texts), max_len_target, num_words_output),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb5896-eb63-4848-af80-150dea3502b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the values\n",
    "for i,d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        if word > 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19aa8585-d0a7-4162-8a20-eb26a3f2830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### build the model ###\n",
    "\n",
    "# set up the encoder - simple!\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(LATENT_DIM, return_sequences=True))\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "# set up the deocder - not so simple\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "\n",
    "# this word embedding will not use pre-trained vectors\n",
    "# although you could\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n",
    "### Attention ###\n",
    "# attention layers need to be global because\n",
    "# they will be repeated by Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer= Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n",
    "\n",
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1), ....., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "    # copy s(t-1) Tx times\n",
    "    # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "    # Concatenate all h(t)'s with s(t-1)\n",
    "    # now shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h,st_1])\n",
    "\n",
    "    # Neural net first layer\n",
    "    x = attn_dense1(x)\n",
    "    print(\"dense 1 shape:\",x.shape)\n",
    "    # Neural net second layer with special softmax over time\n",
    "    alphas = attn_dense2(x)\n",
    "    print(\"dense 2 shape:\",alphas.shape)\n",
    "    # \"Dot\" the alphas and the h's\n",
    "    # remember a.dot(b) = sum over a[t] * b[t]\n",
    "    context = attn_dot([alphas, h])\n",
    "    print(\"context.shape:\", context.shape ) # \n",
    "\n",
    "    return context\n",
    "\n",
    "# define the rest of the decoder(after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a791059-4023-4c8a-82ff-59364747ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)\n",
    "\n",
    "# Unlike previous seq2seq,\n",
    "# we cannot get the output\n",
    "# all in one step\n",
    "# instead we need to do Ty steps\n",
    "# and in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s,c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2f84f3-5981-4711-9022-4d07120f50dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense 1 shape: (None, 6, 10)\n",
      "dense 2 shape: (None, 6, 1)\n",
      "context.shape: (None, 1, 800)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decoder_inputs_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# we need a different layer for each time step\u001b[39;00m\n\u001b[0;32m      8\u001b[0m selector \u001b[38;5;241m=\u001b[39m Lambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[:, t:t\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 9\u001b[0m xt \u001b[38;5;241m=\u001b[39m selector(\u001b[43mdecoder_inputs_x\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxt.shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, xt\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# combine\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'decoder_inputs_x' is not defined"
     ]
    }
   ],
   "source": [
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "    # get the context using attention\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "    # we need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "    \n",
    "    # combine\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "    # pass the combined [context, last word] into LSTM\n",
    "    # along with [s,c]\n",
    "    # get the new [s,c] and output\n",
    "    o,s,c = decoder_lstm(decoder_lstm_input, initial_state=[s,c])\n",
    "\n",
    "    # final dense layer yo get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)\n",
    "\n",
    "    # 'outputs' is now a list of length Ty\n",
    "    # each element is of shape (batch size, output vocab size)\n",
    "    # therefore if we simply stack all the outputs into 1 tensor\n",
    "    # it would be of shape T x N x D\n",
    "    # we would like it to be of shape N x T x D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db82a2b0-6259-4f27-8567-fe7d2ace28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_transpose(x):\n",
    "    # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "    x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "    x = K.permute_dimensions(x, pattern=(1,0,2)) # is now batch_size x T x output_vocab_size\n",
    "    return x\n",
    "\n",
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4199bb5e-84b3-4308-98f6-dd56dcbe92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(inputs=[encoder_inputs_placeholder, decoder_inputs_placeholder, \n",
    "                      initial_s, initial_c],outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f83e3c85-6ee1-4f99-b192-f9418b3b3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # both are of shape N x T x K\n",
    "    mask = K.cast(y_true >0, dtype='float32')\n",
    "    out = mask * y_true * K.log(y_pred)\n",
    "    return -K.sum(out) / K.sum(mask)\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    # both are of shape N x T x K\n",
    "    targ = K.argmax(y_true, axis=-1)\n",
    "    pred = K.argmax(y_pred, axis=-1)\n",
    "    correct = K.cast(K.equal(targ, pred), dtype='float32')\n",
    "    n_total = K.sum(mask)\n",
    "    return n_correct / n_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcba10db-e77c-488a-bceb-0ebf93d53bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\te20312262\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.29 GiB for an array with shape (16000, 10, 10554) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(encoder_inputs), LATENT_DIM_DECODER)) \u001b[38;5;66;03m# initial [s, c]\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mdecoder_targets_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:91\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mNote that this function could return cached copies of created constants for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     88\u001b[0m   \u001b[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001b[39;00m\n\u001b[0;32m     89\u001b[0m   \u001b[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001b[39;00m\n\u001b[0;32m     90\u001b[0m   \u001b[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ops\u001b[38;5;241m.\u001b[39mEagerTensor):\n\u001b[0;32m     93\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 6.29 GiB for an array with shape (16000, 10, 10554) and data type float32"
     ]
    }
   ],
   "source": [
    "# compile the model \n",
    "model.compile(optimizer='adam', loss=custom_loss, metrics=[acc])\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# train the model\n",
    "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit([encoder_inputs, decoder_inputs, z, z], \n",
    "              decoder_targets_one_hot,batch_size=BATCH_SIZE, epochs=EPOCHS, \n",
    "              validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed1afdd9-e2f1-409f-9244-926ed255e15f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# plot some data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mr\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(r\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46be0a-eced-4a91-9e5e-912bd61ddb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make predictions ###\n",
    "# as with peotry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "# the encoder will be stand-alone\n",
    "# from this we will get our initial decoder hidden state\n",
    "# i.e h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e9b7d-2026-481d-a8c0-aba631aa0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644efc72-6723-41cc-a66f-f139a2531738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we don't really need the final stack and transpose\n",
    "# because there's only 1 output\n",
    "# it is already of size N X D\n",
    "# no need to make it 1 x N x D --> N x 1 x D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9f4be-86f5-4a30-b014-3d0d83c7e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(inputs=[decoder_inputs_single,\n",
    "                              encoder_outputs_as_input, initial_s, initial_c],\n",
    "                      outputs=[decoder_outputs, s,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d733cdf9-506c-49f5-82b7-4eefe528c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    # Note: tokenizer lower-cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    # [s, c] will be updated in each loop iteration\n",
    "    s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "    # create the translation\n",
    "    output_sentence = []\n",
    "    for _ in range(max_len_target):\n",
    "        o,s,c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "\n",
    "        # get next word\n",
    "        idx = np.argmax(o.flatten())\n",
    "\n",
    "        # End sentence of EOS\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # update the decoder input\n",
    "        # which is the just the word just generated\n",
    "        target_seq[0,0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370dc3c2-ce88-419a-ba05-50873261e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Do some test translations\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_texts[i])\n",
    "    print(\"Predicted translation:\", translation)\n",
    "    print(\"Actual translation:\", target_texts[i])\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
